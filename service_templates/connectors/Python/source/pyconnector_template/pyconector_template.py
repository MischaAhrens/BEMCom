#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
This is a template for building BEMCom connectors with Python.

The control flow and concepts are very similar to the Node-RED connector
template. You might want to instpect the Main flow of the Node-RED connector
template first to familiarize yourself with these.
"""
import json
import logging
from datetime import datetime

from paho.mqtt.client import Client


logger = logging.getLogger("pyconnector template")


class MQTTHandler(logging.StreamHandler):
    """
    A logging handler that allows publishing log messages on a MQTT broker.
    """

    def __init__(self, mqtt_client, log_topic):
        """
        Set up Handler.

        Assumes that mqtt_client is already initialized, i.e. that the log
        handler can use it directly for publishing and does not need to
        connect or similar. The later is handled by the connector already,
        hence there is no need to reproduce this here.

        Parameters
        ----------
        mqtt_client : class
            Initialized Mqtt client library with signature of paho mqtt.
        log_topic : string
            The topic on which this handler publishes the log messages.
        """
        super().__init__()
        self.mqtt_client = mqtt_client
        self.log_topic = log_topic

    def emit(self, record):
        """
        Publish log recored on MQTT broker.

        Parameters
        ----------
        record : logging.LogRecord
            The record to publish.
        """
        log_msg = {
            "timestamp": datetime.timestamp(datetime.utcnow()) * 1000,
            "msg": record.msg,
            "emitter": record.funcName,
            "level": record.levelno,
        }

        self.mqtt_client.publish(
            payload=json.dumps(log_msg),
            topic=self.log_topic,
        )


class SensorFlow():
    """
    Bundles all functionality to handle sensor messages.

    This is a template for a SensorFlow class, i.e. one that holds all
    functions that are necessary to handle messages from the device(s)
    towards the message broker. The methods could also be implemented
    into the Connector class, but are seperated to support clarity.

    Overload these functions
    ------------------------
    In order to transform this class into operational code you need
    to inherit from it and overload the following methods:
     - receive_raw_msg
     - parse_raw_msg

    Connector Methods
    -----------------
    The connector must provide the following methods to allow correct
    operation of the methods in this class:
     - update_available_datapoints

    Connector Attributes
    --------------------
    The following attributes must be set up by the connector to
    allow these methods to run correctly:

    mqtt_client : class
        Mqtt client library with signature of paho mqtt.
    SEND_RAW_MESSAGE_TO_DB : bool
        Indicates whether the raw message will be sent to designated DB or not.
    MQTT_TOPIC_RAW_MESSAGE_TO_DB : string
        The topic which on which the raw messages will be published.
    datapoint_map : dict of dict.
        Mapping from datapoint key to topic. Is generated by the AdminUI.
        Looks e.e. like this:
            datapoint_map = {
                "sensor": {
                    "Channel__P__value__0": "example-connector/msgs/0001",
                    "Channel__P__unit__0": "example-connector/msgs/0002",
                },
                "actuator": {
                    "example-connector/msgs/0003": "Channel__P__setpoint__0",
                }
            }
        Note thereby that the keys "sensor" and "actuator"" must alaways be
        present, even if the child dicts are empty.
    """

    def run_sensor_flow(self, raw_data=None):
        """
        Processes data received from a device/gateway.

        Parameters
        ----------
        raw_data : TYPE, optional
            Raw data of device/gateway if the device pushes and is not
            pulled for data. The default is None.
        """
        msg = self.receive_raw_msg(raw_data=raw_data)

        # Add receival timestamp in milliseconds since epoch.
        # (Following the message format.)
        ts_utc_now = round(datetime.timestamp(datetime.utcnow()) * 1000)
        msg["payload"]["timestamp"] = ts_utc_now

        # Send raw msg to raw message DB if activated in settings.
        # Handle bytes, as these are not JSON serializable.
        if self.SEND_RAW_MESSAGE_TO_DB:
            payload = msg["payload"]
            if isinstance(payload["raw_message"], (bytes, bytearray)):
                payload["raw_message"] = {
                    "bytes": payload["raw_message"].decode()
                }

            topic = self.MQTT_TOPIC_RAW_MESSAGE_TO_DB
            self.mqtt_client.publish(
                payload=json.dumps(payload),
                topic=topic,
                qos=2,  # Ensures the message is received by the raw msg DB.
            )

        # Parse raw content to dict of dict.
        msg = self.parse_raw_msg(self, raw_msg=msg)

        # Flatten the parsed message to a single level dict.
        msg = self.flatten_parsed_msg(self, parsed_msg=msg)

        # Check if we found new datapoints in this message and need to
        # send an update to the AdminUI.
        available_datapoints_update = {
            "actuator": {},
            "sensor": msg["payload"]["flattened_message"]
        }
        self.update_available_datapoints(
            available_datapoints=available_datapoints_update
        )

        # Publish values of datapoints that have been selected for such
        # within the AdminUI.
        self.filter_and_publish_datapoint_values(flattened_msg=msg)


    def receive_raw_msg(self, raw_data=None):
        """
        Functionality to receive a raw message from device.

        Poll the device/gateway for data and transforms this raw data
        into the format epxected by run_sensor_flow. If the device/gateway
        uses some protocol that pushes data, the raw data should be passed
        as the raw_data argument to the function.

        Parameters
        ----------
        raw_data : TYPE, optional
            Raw data of device/gateway if the device pushes and is not
            pulled for data. The default is None.

        Returns
        -------
        msg : dict
            The message object containing the raw unprocessed data.
            Should be formated like this:
                msg = {
                    "payload": {
                        "raw_message": <the raw data>
                    }
                }
            E.g.
                msg = {
                    "payload": {
                        "raw_message": "device_1:{sensor_1:2.12,sensor_2:3.12}"
                    }
                }
        """
        raise NotImplementedError("receive_raw_msg has not been implemented.")

    def parse_raw_msg(self, raw_msg):
        """
        Functionality to receive a raw message from device.

        Poll the device/gateway for data and transforms this raw data
        into the format epxected by run_sensor_flow. If the device/gateway
        uses some protocol that pushes data, the raw data should be passed
        as the raw_data argument to the function.

        Be aware: All keys in the output message should be strings. All values
        should be converted be strings, too.

        Parameters
        ----------
        raw_msg : dict.
            Raw msg with data from device/gateway. Should be formated like:
                msg = {
                    "payload": {
                        "raw_message": <the raw data>,
                        "timestamp": <milliseconds since epoch>
                    }
                }

        Returns
        -------
        msg : dict
            The message object containing the parsed data as python dicts from
            dicts strucuture.
            Should be formated like this:
                msg = {
                    "payload": {
                        "parsed_message": <the parsed data as object>,
                        "timestamp": <milliseconds since epoch>
                    }
                }
            E.g:
                msg = {
                    "payload": {
                        "parsed_message": {
                            "device_1": {
                                "sensor_1": "2.12",
                                "sensor_2": "3.12"
                            }
                        },
                        "timestamp": 1573680749000
                    }
                }
        """
        raise NotImplementedError("parse_raw_msg has not been implemented.")

    def flatten_parsed_msg(self, parsed_msg):
        """
        Flattens parsed object, i.e. transforms to single layer dict.

        Parameters
        ----------
        msg : dict
            The message object containing the parsed data as python dicts from
            dicts strucuture.
            Should be formated like this:
                msg = {
                    "payload": {
                        "parsed_message": <the parsed data as object>,
                        "timestamp": <milliseconds since epoch>
                    }
                }

        Returns
        -------
        msg : dict
            The message object containing the flattened data.
            Should be formated like this:
                msg = {
                    "payload": {
                        "flattened_message": <the flattend object>,
                        "timestamp": <milliseconds since epoch>
                    }
                }
            E.g:
                msg = {
                    "payload": {
                        "flattened_message": {
                            "device_1__sensor_1": "2.12",
                            "device_1__sensor_2": "3.12"
                        },
                        "timestamp": 1573680749000
                    }
                }
        """
        msg = parsed_msg

        unflat = msg["payload"].pop("parsed_message")
        unflat_next = {}
        flattened = {}

        while unflat:
            for k, v in unflat.items():
                # This is a value, stop iteration for this entry.
                if not isinstance(v, dict):
                    flattened[k] = v
                    continue

                # Here the value is another dict. Dig deeper.
                for k_child, v_child in v.items():
                    k_merged = "__".join([k, k_child])
                    unflat_next[k_merged] = v_child

            unflat = unflat_next
            unflat_next = {}

        msg["payload"]["flattened_message"] = flattened

        return msg

    def filter_and_publish_datapoint_values(self, flattened_msg):
        """
        Generate and send value messages for selected datapoints.

        datapoints are selected via the datapoint_map attribute.

        Parameters
        ----------
        flattened_msg : dict
            The message object containing the flattened data.
            Should be formated like this:
                msg = {
                    "payload": {
                        "flattened_message": <the flattend object>,
                        "timestamp": <milliseconds since epoch>
                    }
                }
        """
        flattened_message = flattened_msg["payload"]["flattened_message"]
        for topic, value in flattened_message.items():
            # Skip all not selected datapoints
            if topic not in self.datapoint_map["sensor"]:
                continue

            # By definition (message convention) the value should always be
            # a string, and the upstream functions should have formated value
            # as a string already, but better save then sorry here.
            value_msg = {
                "value": str(value),
                "timestamp": flattened_msg["payload"]["timestamp"],
            }

            self.mqtt_client.publish(
                topic=topic,
                payload=json.dumps(value_msg)
            )


class ActuatorFlow():
    """
    Bundles all functionality to handle actuator messages.

    This is a template for a ActuatorFlow class, i.e. one that holds all
    functions that are necessary to handle messages from the message
    broker towards the devices/gateway. The methods could also be implemented
    into the Connector class, but are seperated to support clarity.

    Overload these functions
    ------------------------
    In order to transform this class into operational code you need
    to inherit from it and overload the following methods:
     - send_command

    Connector Attributes
    --------------------
    The following attributes must be set up by the connector to
    allow these methods to run correctly:

    datapoint_map : dict of dict.
        Mapping from datapoint key to topic. Is generated by the AdminUI.
        Looks e.e. like this:
            datapoint_map = {
                "sensor": {
                    "Channel__P__value__0": "example-connector/msgs/0001",
                    "Channel__P__unit__0": "example-connector/msgs/0002",
                },
                "actuator": {
                    "example-connector/msgs/0003": "Channel__P__setpoint__0",
                }
            }
        Note thereby that the keys "sensor" and "actuator"" must alaways be
        present, even if the child dicts are empty.
    """

    def run_actuator_flow(self, value_msg_json):
        """
        Processes an actuator value message and sends it to the actuator
        datapoint.

        Parameters
        ----------
        value_msg_json : string.
            The value message that should be sent to the actuator encoded
            in JSON.
        TODO This is unfinished.
        """
        value_msg = json.loads(value_msg_json)


    def send_command(key, value):
        """
        Send message to target device/gateway.


        Parameters
        ----------
        key : TYPE
            DESCRIPTION.
        value : TYPE
            DESCRIPTION.

        Returns
        -------
        None.

        """
        raise NotImplementedError("send_command has not been implemented.")


class Connector():
    """
    The generic logic of the connector.

    Handles connections, threads, triggers pulls, ...

    Configuration Attributes
    ------------------------
    Confiugration will be populated from environment variables on init.
    CONNECTOR_NAME : string
        The name of the connector instance as seen by the AdminUI.
    MQTT_TOPIC_LOGS : string
        The topics used by the log handler to publish log messages on.
    MQTT_TOPIC_HEARTBEAT : string
        The topics used by the connector to publish heartbeats on.
    MQTT_TOPIC_AVAILABLE_DATAPOINTS : string
        The topic on which the available datapoints will be published.
    MQTT_TOPIC_DATAPOINT_MAP : string
        The topic the connector will listen on for datapoint maps
    SEND_RAW_MESSAGE_TO_DB : bool
        Indicates whether the raw message will be sent to designated DB or not.
    MQTT_TOPIC_RAW_MESSAGE_TO_DB : string
        The topic which on which the raw messages will be published.

    Computed Attributes
    -------------------
    These attriubutes are created by init and are then dynamically used
    by the Connector.
    mqtt_client : class
        Mqtt client library with signature of paho mqtt.
    available_datapoints : dict of dict.
        Lists all datapoints known to the connector and is sent to the
        AdminUI. Actuator datapoints must be specified manually. Sensor
        datapoints are additionally automatically added once a value for
        a new datapoint is received. The object contains the connector
        internal key and a sample and value looks e.g. like this:
            available_datapoints = {
                "sensor": {
                    "Channel__P__value__0": 0.122,
                    "Channel__P__unit__0": "kW",
                },
                "actuator": {
                    "Channel__P__setpoint__0": 0.4,
                }
            }
    datapoint_map : dict of dict.
        Mapping from datapoint key to topic. Is generated by the AdminUI.
        Looks e.e. like this:
            datapoint_map = {
                "sensor": {
                    "Channel__P__value__0": "example-connector/msgs/0001",
                    "Channel__P__unit__0": "example-connector/msgs/0002",
                },
                "actuator": {
                    "example-connector/msgs/0003": "Channel__P__setpoint__0",
                }
            }
        Note thereby that the keys "sensor" and "actuator"" must alaways be
        present, even if the child dicts are empty.
    """

    def __init__(self, datapoint_map=None, available_datapoints=None):
        """
        Parameters
        ----------
        datapoint_map : dict of dicts, optional.
            The initial datapoint_map before updating per MQTT. Format is
            specified in the class attriubte docstring above.
        available_datapoints : dict of dicts, optional.
            The initial available_datapoints object before updating per MQTT.
            Format is specified in the class attriubte docstring above.
        """

        self.datapoint_map = {"sensor": {}, "actuator": {}}
        if datapoint_map is not None:
            self.validate_and_update_datapoint_map(
                datapoint_map_json=json.dumps(datapoint_map)
            )

        self.available_datapoints = {"sensor": {}, "actuator": {}}
        if available_datapoints is not None:
            self.update_available_datapoints(
                available_datapoints=available_datapoints
            )


    def validate_and_update_datapoint_map(self, datapoint_map_json):
        """
        Inspects a newly received datapoint_map and stores it if it is valid.

        This function is intended to be used directly within the on_message
        callback and takes thus a jsonized datapoint as input.

        Errors in datapoint_map format will be logged but not raised, as we
        expect it is better to continue running the connector with an outdated
        datapoint map then shutting it down.

        Finally, changes for actuator part of the map will also have an effect
        on the subscribed topics, as new entries may require the subscription
        of the new topic, or deprecated entries may trigger an unsubscribe.

        Parameters
        ----------
        datapoint_map_json : string
            datapoint_map to validate and store in JSON format.
            Format is specified in the class attriubte docstring above.
        """
        datapoint_map = json.loads(datapoint_map_json)
        if not "sensor" in datapoint_map:
            logger.error("No sensor key in datapoint_map. Cancel update.")
            return
        if not "actuator" in datapoint_map:
            logger.error("No actuator key in datapoint_map. Cancel update.")
            return
        if not isinstance(datapoint_map["sensor"], dict):
            logger.error(
                "Sensor entry in datapoint_map contains contains no dict."
                "Cancel update."
            )
            return
        if not isinstance(datapoint_map["actuator"], dict):
            logger.error(
                "Actuator entry in datapoint_map contains contains no dict."
                "Cancel update."
            )
            return

        # Update subscription for actuator datapoints.
        actuator_topics_new = set(datapoint_map["actuator"].keys())
        actuator_topics_old = set(self.datapoint_map["actuator"].keys())
        new_topics = actuator_topics_new.difference(actuator_topics_old)
        removed_topics = actuator_topics_old.difference(actuator_topics_new)
        for topic in removed_topics:
            self.mqtt_client.unsubscribe(topic=topic)
        for topic in new_topics:
            # Ensure actuator messages are delivered once and only once.
            self.mqtt_client.subscribe(topic=topic, qos=2)

        self.datapoint_map = datapoint_map

    def update_available_datapoints(self, available_datapoints):
        """
        Updates the available_datapoint dict.

        Will always update the sample values but only send and update to the
        AdminUI if a new datapoint has been found.

        Parameters
        ----------
        available_datapoints : dict of dicts.
            Connector internal keys and example values for available_datapoints
            to store and optionally publish. Format is specified in the class
            attriubte docstring above.
        """
        available_datapoints_old = self.available_datapoints

        # Check if the update to available_datapoints introduces new keys
        new_keys_found = False
        for dpt in ["sensor", "actuator"]:
            existing_keys = set(available_datapoints_old[dpt].keys())
            updated_keys = set(available_datapoints[dpt].keys())
            if updated_keys.difference(existing_keys):
                new_keys_found = True
                break

        # Update the example values
        for dpt in ["sensor", "actuator"]:
            available_datapoints_old[dpt].update(available_datapoints[dpt])

        # Store the updated map
        self.available_datapoints = available_datapoints_old

        # Publish if new keys found.
        if new_keys_found:
            self.mqtt_client.publish(
                payload=json.dumps(self.available_datapoints),
                topic=self.MQTT_TOPIC_AVAILABLE_DATAPOINTS,
            )
