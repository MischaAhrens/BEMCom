#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import json
import time
import logging
from datetime import datetime, timezone
from unittest.mock import MagicMock

import pytest
from paho.mqtt.client import Client

from .base import TestClassWithFixtures
from pyconnector_template.pyconnector_template import MQTTHandler
from pyconnector_template.pyconnector_template import SensorFlow, Connector
from pyconnector_template.pyconnector_template import ActuatorFlow


class RecursiveMagicMock(MagicMock):
    """
    Once initialized this mock just returns itself instead of new mock
    object. This allows you to test wether the init calls where correct.
    """

    def __call__(self, *args, **kwargs):
        # This is required that all mock calls are stored.
        _ = super().__call__(*args, **kwargs)
        return self


class TestMQTTHandler__Init__(TestClassWithFixtures):

    fixture_names = []

    def test_args_stored_as_attributes(self):
        """
        Verify that the necessary attributes are generated by __init__
        """
        mqtt_client = MagicMock()
        log_topic = MagicMock()

        handler = MQTTHandler(mqtt_client=mqtt_client, log_topic=log_topic)

        assert id(handler.mqtt_client) == id(mqtt_client)
        assert id(handler.log_topic) == id(log_topic)


class TestMQTTHandlerEmit(TestClassWithFixtures):

    fixture_names = ()

    def setup_class(self):

        self.mqtt_client = MagicMock()
        self.log_topic = MagicMock()

        self.mh = MQTTHandler(
            mqtt_client=self.mqtt_client, log_topic=self.log_topic
        )

        self.logger = logging.getLogger("TestMQTTHandler")
        self.logger.setLevel(logging.INFO)
        self.logger.addHandler(self.mh)

    def test_topic_correct(self):
        """
        Check that the message is published on the correct topic.
        """
        self.logger.info("A test")

        expected_topic = self.log_topic
        actual_topic = self.mh.mqtt_client.publish.call_args.kwargs["topic"]
        assert actual_topic == expected_topic

    def test_payload_correct(self):
        """
        Verify that the emitted payload matches the BEMCom message convention.
        """
        # - 1 in case it rounds up.
        log_ts = round(datetime.now(tz=timezone.utc).timestamp() * 1000) - 1
        self.logger.info("A test")

        # Check that the message is as expected, but not for the timestamp,
        # as we don't know exactly what timestamp has been used.
        expected_payload = {
            "timestamp": log_ts,
            "msg": "A test",
            "emitter": "test_payload_correct",
            "level": logging.INFO,
        }
        expected_timestamp = expected_payload.pop("timestamp")
        actual_payload = json.loads(
            self.mh.mqtt_client.publish.call_args.kwargs["payload"]
        )
        actual_timestamp = actual_payload.pop("timestamp")

        assert actual_payload == expected_payload

        # Check that the actual timestamp is between the time this function
        # has started and 10 seconds later, which should be ok even on very
        # slow machines.
        assert actual_timestamp >= expected_timestamp
        assert actual_timestamp < expected_timestamp + 10000

    def test_payload_correct_with_objects_to_format(self):
        """
        Verify that the emitted payload matches the BEMCom message convention,
        also when the logger is given additional objects to format the msg.
        """
        # - 1 in case it rounds up.
        log_ts = round(datetime.now(tz=timezone.utc).timestamp() * 1000) - 1
        self.logger.info("A test: %s", [1, 2])

        # Check that the message is as expected, but not for the timestamp,
        # as we don't know exactly what timestamp has been used.
        expected_payload = {
            "timestamp": log_ts,
            "msg": "A test: [1, 2]",
            "emitter": "test_payload_correct_with_objects_to_format",
            "level": logging.INFO,
        }
        expected_timestamp = expected_payload.pop("timestamp")
        actual_payload = json.loads(
            self.mh.mqtt_client.publish.call_args.kwargs["payload"]
        )
        actual_timestamp = actual_payload.pop("timestamp")

        assert actual_payload == expected_payload

        # Check that the actual timestamp is between the time this function
        # has started and 10 seconds later, which should be ok even on very
        # slow machines.
        assert actual_timestamp >= expected_timestamp
        assert actual_timestamp < expected_timestamp + 10000


class TestSensorFlowRun(TestClassWithFixtures):

    fixture_names = []

    def setup_method(self, method):

        self.sf = SensorFlow()
        self.sf.version = "0.0.1"

        # Patch receive_raw_msg and add return value with realistic signature.
        self.raw_msg_return = {
            "payload": {
                "raw_message": '{"dp_1": 2.1, "dp_2": "ok"}',
            }
        }
        self.sf.receive_raw_msg = MagicMock(return_value=self.raw_msg_return)

        # There is no control flow after the check for raw message DB that
        # would depend on the content of the message. Just use these
        # to check if the mehtods are called.
        self.sf.parse_raw_msg = MagicMock()
        self.sf._flatten_parsed_msg = MagicMock()
        self.sf._update_available_datapoints = MagicMock()
        self.sf._filter_and_publish_datapoint_values = MagicMock()

        # Overload configuration that would be provided by the Connector.
        self.sf.mqtt_client = MagicMock()
        self.sf.SEND_RAW_MESSAGE_TO_DB = "FALSE"
        self.sf.MQTT_TOPIC_RAW_MESSAGE_TO_DB = "tpyco/raw_message_to_db"

    def test_receive_raw_msg_is_called(self):
        """
        This function is an essential part of the run logic.
        """
        self.sf.run_sensor_flow()
        self.sf.receive_raw_msg.assert_called()

    def test_timestamp_in_message(self):
        """
        Value messages must contain timestemps (see BEMCom message format).
        """
        self.sf.run_sensor_flow()

        msg = self.sf.parse_raw_msg.call_args.kwargs["raw_msg"]

        assert "timestamp" in msg["payload"]

    def test_timestamp_correct_value(self):
        """
        Verify that the timestamp of the message is correctly now in UTC.

        For that sake we comute the correct timestamp at beginning of the test
        and expect that the computed value is the range between this value
        and 10 seconds later, which should be realistic even on VERY slow
        machines.
        """
        expected_ts = round(datetime.now(tz=timezone.utc).timestamp() * 1000)

        self.sf.run_sensor_flow()

        msg = self.sf.parse_raw_msg.call_args.kwargs["raw_msg"]
        actual_ts = msg["payload"]["timestamp"]

        assert actual_ts >= expected_ts
        assert actual_ts < expected_ts + 10000

    def test_no_send_raw_msg_to_db_on_false(self):
        """
        Validate that no raw message is sent to the raw message DB if this
        option is deactivated via setting flag.
        """
        self.sf.SEND_RAW_MESSAGE_TO_DB = "FALSE"

        self.sf.run_sensor_flow()

        # publish should only been called once, i.e. for sending
        # final message.
        assert self.sf.mqtt_client.publish.call_count == 0

    def test_send_raw_msg_to_db(self):
        """
        Check that the raw message is sent to raw message db if this option
        is set.
        """
        self.sf.SEND_RAW_MESSAGE_TO_DB = "TRUE"

        self.sf.run_sensor_flow()

        expected_payload = {
            "payload": self.raw_msg_return["payload"],
            "connector_version": self.sf.version,
        }
        expected_topic = self.sf.MQTT_TOPIC_RAW_MESSAGE_TO_DB
        # Ensure the message is received by the raw message DB.
        expected_qos = 2

        publish_call = self.sf.mqtt_client.publish.call_args_list[0]
        actual_topic = publish_call.kwargs["topic"]
        actual_payload = json.loads(publish_call.kwargs["payload"])
        actual_qos = publish_call.kwargs["qos"]

        assert expected_payload == actual_payload
        assert expected_topic == actual_topic
        assert expected_qos == actual_qos

    def test_send_raw_msg_to_db_bytes(self):
        """
        Check that the raw message is sent to raw message db if this option
        is set. Here check special handling if raw message is in bytes,
        as bytes cannot be serialized to JSON, hence we expect an exception
        in contrast to earlier versions of the code, which have parsed it to
        string. However this is inconsistent.

        """
        self.sf.SEND_RAW_MESSAGE_TO_DB = "TRUE"
        raw_msg_bytes_return = {
            "payload": {"raw_message": b"some bytes and stuff"}
        }
        self.sf.receive_raw_msg = MagicMock(return_value=raw_msg_bytes_return)

        with pytest.raises(TypeError):
            self.sf.run_sensor_flow()

    def test_parse_raw_msg_called(self):
        """
        This function is an essential part of the run logic.
        """
        self.sf.run_sensor_flow()
        self.sf.parse_raw_msg.assert_called()

    def test_flatten_parsed_msg_called(self):
        """
        This function is an essential part of the run logic.
        """
        self.sf.run_sensor_flow()
        self.sf._flatten_parsed_msg.assert_called()

    def test_update_available_datapoints_called(self):
        """
        This function is an essential part of the run logic.
        """
        self.sf.run_sensor_flow()
        self.sf._update_available_datapoints.assert_called()

    def test_update_available_datapoints_called_with_correct_arg(self):
        """
        Verify that the argument to update_available_datapoint has the
        expected format.
        """
        flattened_msg = {
            "payload": {
                "flattened_message": {
                    "device_1__sensor_1": "2.12",
                    "device_1__sensor_2": "3.12",
                },
                "timestamp": 1573680749000,
            }
        }
        self.sf._flatten_parsed_msg = MagicMock(return_value=flattened_msg)

        self.sf.run_sensor_flow()

        expected_available_datapoints = {
            "sensor": {
                "device_1__sensor_1": "2.12",
                "device_1__sensor_2": "3.12",
            },
            "actuator": {},
        }
        uad_kwargs = self.sf._update_available_datapoints.call_args.kwargs
        actual_available_datapoints = uad_kwargs["available_datapoints"]
        assert expected_available_datapoints == actual_available_datapoints

    def test_filter_and_publish_datapoint_values_called(self):
        """
        This function is an essential part of the run logic.
        """
        self.sf.run_sensor_flow()
        self.sf._filter_and_publish_datapoint_values.assert_called()

    def test_raw_messages_with_None_will_be_caught(self):
        """
        Check that receive_raw_msg has the option to drop an incoming msg,
        by setting the payload to None.
        """
        self.sf.receive_raw_msg = MagicMock(return_value={"payload": None})
        self.sf.run_sensor_flow()
        assert not self.sf.parse_raw_msg.called

    def test_parsed_messages_with_None_will_be_caught(self):
        """
        Check that parsed_msg has the option to drop an incoming msg,
        by setting the payload to None.
        """
        self.sf.parse_raw_msg = MagicMock(return_value={"payload": None})
        self.sf.run_sensor_flow()
        assert not self.sf._flatten_parsed_msg.called


class TestSensorFlowFlattenParsedMsg(TestClassWithFixtures):

    fixture_names = []

    def setup_method(self, method):

        self.sf = SensorFlow()

        self.parsed_msg = {
            "payload": {
                "parsed_message": {
                    "device_1": {"sensor_1": "2.12", "sensor_2": "3.12"}
                },
                "timestamp": 1573680749000,
            }
        }

        self.parsed_msg_deeper = {
            "payload": {
                "parsed_message": {
                    "device_1": {"sensor_1": "2.12", "sensor_2": "3.12"},
                    "device_2": {"0": {"sensor_1": "ok"}},
                },
                "timestamp": 1573680749000,
            }
        }

    def test_output_format_correct(self):
        """
        Verify that the output of the function is flattened as expected.
        """
        expected_msg = {
            "payload": {
                "flattened_message": {
                    "device_1__sensor_1": "2.12",
                    "device_1__sensor_2": "3.12",
                },
                "timestamp": self.parsed_msg["payload"]["timestamp"],
            }
        }

        actual_msg = self.sf._flatten_parsed_msg(parsed_msg=self.parsed_msg)

        assert actual_msg == expected_msg

    def test_output_format_deeper_correct(self):
        """
        Verify that the output of the function is flattened as expected, also
        for an input with varying depth and more then 2 layers.
        """
        expected_msg = {
            "payload": {
                "flattened_message": {
                    "device_1__sensor_1": "2.12",
                    "device_1__sensor_2": "3.12",
                    "device_2__0__sensor_1": "ok",
                },
                "timestamp": self.parsed_msg["payload"]["timestamp"],
            }
        }

        actual_msg = self.sf._flatten_parsed_msg(
            parsed_msg=self.parsed_msg_deeper
        )

        assert actual_msg == expected_msg


class TestSensorFlowFilterAndPublish(TestClassWithFixtures):

    fixture_names = ("caplog",)

    def setup_method(self, method):

        self.sf = SensorFlow()
        self.sf.mqtt_client = MagicMock()

        self.flattened_msg = {
            "payload": {
                "flattened_message": {
                    "device_1__sensor_1": "1.12",
                    "device_1__sensor_2": 2.12,
                    "device_1__sensor_3": True,
                },
                "timestamp": 1573680749000,
            }
        }

        self.sf.datapoint_map = {
            "sensor": {
                "device_1__sensor_1": "example-connector/msgs/0001",
                "device_1__sensor_2": "example-connector/msgs/0002",
            },
            "actuator": {},
        }

        self.logger_name = "pyconnector"

    def test_value_msgs_published_for_selected_datapoints(self):
        """
        Validate that value messages have been sent out for datapoints
        selected with datapoint_map and not sent for those not selected.
        """
        self.sf._filter_and_publish_datapoint_values(
            flattened_msg=self.flattened_msg
        )

        # Compute the messages that would have been sent by the call above.
        calls = self.sf.mqtt_client.publish.call_args_list
        actual_value_msgs = [json.loads(c.kwargs["payload"]) for c in calls]
        actual_topics = [c.kwargs["topic"] for c in calls]

        flattened_message = self.flattened_msg["payload"]["flattened_message"]
        for dp_key, dp_value in flattened_message.items():
            expected_value_msg = {
                "value": dp_value,
                "timestamp": self.flattened_msg["payload"]["timestamp"],
            }

            # Verify that not selected datapoints have not been sent.
            if dp_key not in self.sf.datapoint_map["sensor"]:
                assert expected_value_msg not in actual_value_msgs
                continue

            # Verify that all selected datapoints have been sent.
            expected_topic = self.sf.datapoint_map["sensor"][dp_key]
            assert expected_topic in actual_topics
            assert expected_value_msg in actual_value_msgs

            # Also verify that the topics and message matches.
            index_topic = actual_topics.index(expected_topic)
            index_value_msg = actual_value_msgs.index(expected_value_msg)
            assert index_topic == index_value_msg

    def test_fallback_to_string_encoding(self):
        """
        At 2021-08-05 the behaviour of the _filter_and_publish_datapoint_values
        method has been changed to send values as JSON encoded strings and not
        always as strings (to allow more efficient DB layouts.)

        As a fallback if JSON encoding fails will send the value as string.
        Verify here that this fallback works as expected.
        """

        flattened_msg = {
            "payload": {
                "flattened_message": {
                    # binnary data cannot be encoded to json.
                    "device_1__sensor_1": b"binary",
                },
                "timestamp": 1573680749000,
            }
        }

        self.sf._filter_and_publish_datapoint_values(
            flattened_msg=flattened_msg
        )

        # Compute the messages that would have been sent by the call above.
        calls = self.sf.mqtt_client.publish.call_args_list
        actual_value_msgs = [json.loads(c.kwargs["payload"]) for c in calls]
        actual_topics = [c.kwargs["topic"] for c in calls]

        flattened_message = flattened_msg["payload"]["flattened_message"]
        for dp_key, dp_value in flattened_message.items():
            expected_value_msg = {
                "value": str(dp_value),
                "timestamp": self.flattened_msg["payload"]["timestamp"],
            }

            # Verify that all selected datapoints have been sent.
            expected_topic = self.sf.datapoint_map["sensor"][dp_key]
            assert expected_topic in actual_topics
            assert expected_value_msg in actual_value_msgs

            # Also verify that the topics and message matches.
            index_topic = actual_topics.index(expected_topic)
            index_value_msg = actual_value_msgs.index(expected_value_msg)
            assert index_topic == index_value_msg

    def test_fallback_to_string_sends_warning(self):
        """
        In extension to the test above, also verify that a warning is raised
        so the user can notice that the connector behaves unexpected.
        """

        self.caplog.set_level(logging.WARNING, logger=self.logger_name)
        self.caplog.clear()
        records = self.caplog.records

        # This should raise no warning.
        self.sf._filter_and_publish_datapoint_values(
            flattened_msg=self.flattened_msg
        )
        assert len(records) == 0

        # But this should.
        flattened_msg = {
            "payload": {
                "flattened_message": {
                    # binnary data cannot be encoded to json.
                    "device_1__sensor_1": b"binary",
                },
                "timestamp": 1573680749000,
            }
        }
        self.sf._filter_and_publish_datapoint_values(
            flattened_msg=flattened_msg
        )
        assert len(records) == 1
        assert records[0].levelname == "WARNING"
        # Without the topic will not know which message went wrong.
        expected_topic = self.sf.datapoint_map["sensor"]["device_1__sensor_1"]
        assert expected_topic in records[0].message


class TestActuatorFlowRun(TestClassWithFixtures):

    fixture_names = ()

    def setup_method(self, method):

        self.af = ActuatorFlow()

        # Prepare the tests by defining the datapoint_map and a matching
        # message with topic and stuff.
        self.test_datapoint_value = "2.1"  # Always a string (message format)
        self.test_datapoint_timestamp = 1573680749000
        self.test_datapoint_key = "device_1__sensor_2"
        self.test_topic = "example-connector/msgs/0002"
        self.test_value_msg_json = json.dumps(
            {
                "value": self.test_datapoint_value,
                "timestamp": self.test_datapoint_timestamp,
            }
        )
        self.af.datapoint_map = {
            "sensor": {},
            "actuator": {
                "example-connector/msgs/0001": "device_1__sensor_1",
                self.test_topic: self.test_datapoint_key,
            },
        }

    def test_send_command_is_called(self):
        """
        This function is an essential part of the run logic.
        """
        self.af.send_command = MagicMock()
        self.af.run_actuator_flow(
            topic=self.test_topic, value_msg_json=self.test_value_msg_json
        )
        self.af.send_command.assert_called()

    def test_send_command_arg_format_correct(self):
        """
        Verify that run_actuator_flow processes the msg correctly to the
        format expected by send_command.
        """
        self.af.send_command = MagicMock()
        self.af.run_actuator_flow(
            topic=self.test_topic, value_msg_json=self.test_value_msg_json
        )
        call_args = self.af.send_command.call_args

        expected_datapoint_key = self.test_datapoint_key
        actual_datapoint_key = call_args.kwargs["datapoint_key"]
        assert actual_datapoint_key == expected_datapoint_key

        expected_datapoint_value = self.test_datapoint_value
        actual_datapoint_value = call_args.kwargs["datapoint_value"]
        assert actual_datapoint_value == expected_datapoint_value

        expected_datapoint_timestamp = self.test_datapoint_timestamp
        actual_datapoint_timestamp = call_args.kwargs["datapoint_timestamp"]
        assert actual_datapoint_timestamp == expected_datapoint_timestamp


class TestConnector__Init__(TestClassWithFixtures):

    fixture_names = ()

    def setup_class(self):
        self.test_CONNECTOR_NAME = "tpyco"
        self.test_SEND_RAW_MESSAGE_TO_DB = "FALSE"
        self.test_DEBUG = "FALSE"
        self.test_MQTT_BROKER_HOST = "localhost"
        self.test_MQTT_BROKER_PORT = "1883"

        # Expose the config as environment variables as would be done
        # by a docker entrypoint script.
        os.environ["CONNECTOR_NAME"] = self.test_CONNECTOR_NAME
        os.environ["SEND_RAW_MESSAGE_TO_DB"] = self.test_SEND_RAW_MESSAGE_TO_DB
        os.environ["DEBUG"] = self.test_DEBUG
        os.environ["MQTT_BROKER_HOST"] = self.test_MQTT_BROKER_HOST
        os.environ["MQTT_BROKER_PORT"] = self.test_MQTT_BROKER_PORT

    def test_environment_variables_loaded(self):
        """
        Verify that all environment variables are loaded and configuration
        attributes are populated as expected.
        """
        self.cn = Connector(version="0.0.1")

        # These should be loaded as they are defined externally.
        assert self.cn.CONNECTOR_NAME == self.test_CONNECTOR_NAME
        assert (
            self.cn.SEND_RAW_MESSAGE_TO_DB == self.test_SEND_RAW_MESSAGE_TO_DB
        )
        assert self.cn.DEBUG == self.test_DEBUG
        assert self.cn.MQTT_BROKER_HOST == self.test_MQTT_BROKER_HOST
        # Paho MQTT expects ports as int, it needs to be parsed thus.
        assert self.cn.MQTT_BROKER_PORT == int(self.test_MQTT_BROKER_PORT)

        # These are computed based on CONNECTOR_NAME
        expected_MQTT_TOPIC_LOGS = self.test_CONNECTOR_NAME + "/logs"
        assert self.cn.MQTT_TOPIC_LOGS == expected_MQTT_TOPIC_LOGS

        expected_MQTT_TOPIC_HEARTBEAT = self.test_CONNECTOR_NAME + "/heartbeat"
        assert self.cn.MQTT_TOPIC_HEARTBEAT == expected_MQTT_TOPIC_HEARTBEAT

        expected_MQTT_TOPIC_AVAILABLE_DATAPOINTS = (
            self.test_CONNECTOR_NAME + "/available_datapoints"
        )
        assert (
            self.cn.MQTT_TOPIC_AVAILABLE_DATAPOINTS
            == expected_MQTT_TOPIC_AVAILABLE_DATAPOINTS
        )

        expected_MQTT_TOPIC_DATAPOINT_MAP = (
            self.test_CONNECTOR_NAME + "/datapoint_map"
        )
        assert (
            self.cn.MQTT_TOPIC_DATAPOINT_MAP
            == expected_MQTT_TOPIC_DATAPOINT_MAP
        )

        expected_MQTT_TOPIC_RAW_MESSAGE_TO_DB = (
            self.test_CONNECTOR_NAME + "/raw_message_to_db"
        )
        assert (
            self.cn.MQTT_TOPIC_RAW_MESSAGE_TO_DB
            == expected_MQTT_TOPIC_RAW_MESSAGE_TO_DB
        )

    def test_args_are_stored(self):
        """
        These need to be stored ad the appropriate places for the run method
        to use.
        """
        version = MagicMock()
        datapoint_map = MagicMock()
        available_datapoints = MagicMock()
        DeviceDispatcher = MagicMock()
        device_dispatcher_kwargs = {}
        MqttClient = MagicMock()
        heartbeat_interval = MagicMock()

        self.cn = Connector(
            version=version,
            datapoint_map=datapoint_map,
            available_datapoints=available_datapoints,
            DeviceDispatcher=DeviceDispatcher,
            device_dispatcher_kwargs=device_dispatcher_kwargs,
            MqttClient=MqttClient,
            heartbeat_interval=heartbeat_interval,
        )

        assert self.cn.version == version
        assert self.cn._initial_datapoint_map == datapoint_map
        assert self.cn._initial_available_datapoints == available_datapoints
        assert self.cn._DeviceDispatcher == DeviceDispatcher
        assert self.cn._device_dispatcher_kwargs == device_dispatcher_kwargs
        assert self.cn._MqttClient == MqttClient
        assert self.cn._heartbeat_interval == heartbeat_interval

    def test_default_args_are_correct(self):
        """
        Verify that default args are interpreted correctly. These are the
        default values that are expected by Connector.run()
        """
        self.cn = Connector(version="0.0.1")

        assert self.cn._initial_datapoint_map is None
        assert self.cn._initial_available_datapoints is None
        assert self.cn._DeviceDispatcher is None
        assert self.cn._device_dispatcher_kwargs == {}  # See class docstring.
        assert self.cn._MqttClient == Client


class TestConnectorRun(TestClassWithFixtures):

    fixture_names = ("caplog",)

    def setup_class(self):
        self.test_CONNECTOR_NAME = "tpyco"
        self.test_SEND_RAW_MESSAGE_TO_DB = "FALSE"
        self.test_DEBUG = "FALSE"
        self.test_MQTT_BROKER_HOST = "localhost"
        self.test_MQTT_BROKER_PORT = "1883"

        # Expose the config as environment variables as would be done
        # by a docker entrypoint script.
        os.environ["CONNECTOR_NAME"] = self.test_CONNECTOR_NAME
        os.environ["SEND_RAW_MESSAGE_TO_DB"] = self.test_SEND_RAW_MESSAGE_TO_DB
        os.environ["DEBUG"] = self.test_DEBUG
        os.environ["MQTT_BROKER_HOST"] = self.test_MQTT_BROKER_HOST
        os.environ["MQTT_BROKER_PORT"] = self.test_MQTT_BROKER_PORT

        self.logger_name = "pyconnector"

        # Some generally useful kwargs for Connector to ensure that
        # run doesn't fail or blocks for ages.
        self.connector_default_kwargs = {
            "version": "0.0.1",
            "MqttClient": MagicMock,
            "heartbeat_interval": 0.05,
        }

    def test_validate_and_update_datapoint_map_is_called(self):
        """
        This function must be called with the correct arguments.

        This test will also fail if validate_and_update_datapoint_map
        is not implemented correctly.
        """
        datapoint_map = {
            "sensor": {},
            "actuator": {
                "example-connector/msgs/0001": "device_1__sensor_1",
            },
        }
        self.cn = Connector(**self.connector_default_kwargs)
        self.cn._initial_datapoint_map = datapoint_map
        self.cn.run()

        expected_datapoint_map = datapoint_map
        actual_datapoint_map = self.cn.datapoint_map
        assert actual_datapoint_map == expected_datapoint_map

    def test_empty_datapoint_map_is_created_default(self):
        """
        Verify that the connector starts with an empty datapoint_map
        by default if no datapoint_map is specified.

        This test will also fail if validate_and_update_datapoint_map
        is not implemented correctly.
        """
        self.cn = Connector(**self.connector_default_kwargs)
        self.cn._initial_datapoint_map = None
        self.cn.run()

        expected_datapoint_map = {"sensor": {}, "actuator": {}}
        actual_datapoint_map = self.cn.datapoint_map
        assert actual_datapoint_map == expected_datapoint_map

    def test_update_available_datapoints_map_is_called(self):
        """
        This function must be called with the correct arguments.

        This test will also fail if update_available_datapoints
        is not implemented correctly.
        """
        available_datapoints = {
            "sensor": {
                "Channel__P__value__0": 0.122,
                "Channel__P__unit__0": "kW",
            },
            "actuator": {
                "Channel__P__setpoint__0": 0.4,
            },
        }
        self.cn = Connector(**self.connector_default_kwargs)
        self.cn._initial_available_datapoints = available_datapoints
        self.cn.run()

        expected_available_datapoints = available_datapoints
        actual_available_datapoints = self.cn.available_datapoints
        assert actual_available_datapoints == expected_available_datapoints

    def test_empty_available_datapoints_is_created_default(self):
        """
        Verify that the connector starts with an empty available_datapoints
        object by default if no available_datapoints is specified.

        This test will also fail if update_available_datapoints
        is not implemented correctly.
        """
        self.cn = Connector(**self.connector_default_kwargs)
        self.cn._initial_available_datapoints = None
        self.cn.run()

        expected_available_datapoints = {"sensor": {}, "actuator": {}}
        actual_available_datapoints = self.cn.available_datapoints
        assert actual_available_datapoints == expected_available_datapoints

    def test_mqtt_initiated_correctly(self):
        """
        Check that the MQTT client has been setup correctly, i.e. that
        all relevant functions have been called and stuff, see below.
        """
        self.cn = Connector(**self.connector_default_kwargs)
        self.cn._MqttClient = RecursiveMagicMock()
        self.cn.run()

        # Test that MQTT client has been called, and received the expected
        # configuration.
        self.cn._MqttClient.assert_called()
        expected_MqttClient_kwargs = {"userdata": {"self": self.cn}}
        actual_MqttClient_kwargs = self.cn._MqttClient.call_args.kwargs
        assert actual_MqttClient_kwargs == expected_MqttClient_kwargs

        # Verify that the on_message callback has been set.
        assert (
            self.cn._MqttClient.on_message == self.cn._handle_incoming_mqtt_msg
        )

        # Check connect has been called with correct args, as we will have no
        # connection to the broker if not. These tests may also fail if
        # there are issues in __init__.
        self.cn._MqttClient.connect.assert_called()

        expected_arg_host = self.test_MQTT_BROKER_HOST
        actual_arg_host = self.cn._MqttClient.connect.call_args.kwargs["host"]
        assert actual_arg_host == expected_arg_host

        expected_arg_port = int(self.test_MQTT_BROKER_PORT)
        actual_arg_port = self.cn._MqttClient.connect.call_args.kwargs["port"]
        assert actual_arg_port == expected_arg_port

        # The client must also subscribe the datapoint_map topic, in order
        # to receive the latest datapoint_maps from the API.
        #
        # TODO: It is important that this subscribe, which will also trigger
        # a processing of any retained datapointmap, is executed only after
        # the default values for datapoint_map are processed to prevent that
        # the API version will be overwritten. You may to test that too.
        assert self.cn._MqttClient.subscribe.called
        expected_topic = self.cn.MQTT_TOPIC_DATAPOINT_MAP
        actual_topic = self.cn._MqttClient.subscribe.call_args.kwargs["topic"]
        assert actual_topic == expected_topic

        # After connect we expect loop_forever to be called in seperate thread.
        self.cn._MqttClient.loop_forever.assert_called()

        # Finally, also disconnect should have been called after loop has
        # been interrupted.
        self.cn._MqttClient.disconnect.assert_called()

    def test_mqtt_log_handler_added(self):
        """
        We expect to find the log handler exactly once in loggers, although
        run has been called very often during the tests.
        """
        self.cn = Connector(**self.connector_default_kwargs)
        self.cn.run()

        logger = logging.getLogger("pyconnector")
        assert sum([isinstance(h, MQTTHandler) for h in logger.handlers]) == 1

    def test_mqtt_log_handler_initiated_correctly(self):
        """
        Verify that MQTTHandler has received the correct args.
        """
        self.cn = Connector(**self.connector_default_kwargs)
        self.cn.run()

        logger = logging.getLogger("pyconnector")
        for handler in logger.handlers:
            if isinstance(handler, MQTTHandler):
                mqtt_handler = handler
                break

        assert mqtt_handler.log_topic == self.cn.MQTT_TOPIC_LOGS
        #
        # TODO: This test would also be usefuly but fails once executing all
        # tests, no clue why.
        # assert mqtt_handler.mqtt_client == self.cn.mqtt_client

    def test_warn_if_device_dispatcher_is_none(self):
        """
        For most cases it will not make sense to run the connector without
        the device_dispatcher, as no data can be received from device or
        gateway. Verify that a warning is issued in such cases.
        """
        self.caplog.set_level(logging.WARNING, logger=self.logger_name)
        self.caplog.clear()

        self.cn = Connector(**self.connector_default_kwargs)
        self.cn._DeviceDispatcher = None
        self.cn.run()

        records = self.caplog.records
        assert records[0].levelname == "WARNING"
        assert "DeviceDispatcher is not set." in records[0].message

    def test_device_dispatcher_is_initiated_correctly(self):
        """
        Verify, that the device dispatcher receives the designated kwargs,
        run_sensor_flow as target function and is executed with start(),
        as these are the neceassry steps for correct opreation.
        """
        device_dispatcher_mock = RecursiveMagicMock()
        device_dispatcher_mock.is_alive = MagicMock(return_value=True)
        device_dispatcher_target_func = MagicMock()
        device_dispatcher_kwargs = {
            "call_interval": 5,
            "target_func": device_dispatcher_target_func,
        }

        self.cn = Connector(**self.connector_default_kwargs)
        self.cn._MqttClient = MagicMock()
        self.cn._DeviceDispatcher = device_dispatcher_mock
        self.cn._device_dispatcher_kwargs = device_dispatcher_kwargs
        self.cn.run()

        # Check that the device dispatcher has been initiated correctly.
        assert device_dispatcher_mock.called

        # Don't reuse the dict from above, it has been changed by the
        # connector class.
        expected_dd_kwargs = {
            "call_interval": 5,
            "target_func": device_dispatcher_target_func,
        }
        actual_dd_kwargs = device_dispatcher_mock.call_args.kwargs
        assert actual_dd_kwargs == expected_dd_kwargs

        # Finally verify the dispatcher has been started as it won't run else.
        assert device_dispatcher_mock.start.called

    def test_device_dispatcher_target_func_falls_back_to_run_sensor_flow(self):
        """
        Verify that if target_func is not specified we fall back to
        cn.run_sensor_flow as this has been the default behaviour until
        version 0.1.3. However we expect a warning.
        """
        self.caplog.set_level(logging.WARNING, logger=self.logger_name)
        self.caplog.clear()

        device_dispatcher_mock = RecursiveMagicMock()
        device_dispatcher_mock.is_alive = MagicMock(return_value=True)
        device_dispatcher_kwargs = {"call_interval": 5}
        run_sensor_flow = MagicMock()

        self.cn = Connector(**self.connector_default_kwargs)
        self.cn.run_sensor_flow = run_sensor_flow
        self.cn._MqttClient = MagicMock()
        self.cn._DeviceDispatcher = device_dispatcher_mock
        self.cn._device_dispatcher_kwargs = device_dispatcher_kwargs
        self.cn.run()

        # Check that the device dispatcher has been initiated correctly.
        assert device_dispatcher_mock.called

        # Don't reuse the dict from above, it has been changed by the
        # connector class.
        expected_dd_kwargs = {
            "call_interval": 5,
            "target_func": run_sensor_flow,
        }
        actual_dd_kwargs = device_dispatcher_mock.call_args.kwargs
        assert actual_dd_kwargs == expected_dd_kwargs

        records = self.caplog.records
        assert records[0].levelname == "WARNING"
        assert "Did not find a target function " in records[0].message

    def test_send_heartbeat_is_called(self):
        """
        Once run has initiated everything and if both dispatchers are alive,
        we expect that a heartbeat would be send. The fake mqtt client will
        wait for 0.25 seconds, after which it terminates and thread is not
        alive anymore. That gives time for three heartbeat messages with an
        interval of 0.1 seconds between two heartbeat messages.
        """
        # Creat a mock for the mqtt client that keeps the broker side
        # thread active for a bit, so it appears that the process is healthy.
        def fake_loop_forever():
            time.sleep(0.25)

        _MqttClient_mock = RecursiveMagicMock()
        _MqttClient_mock.loop_forever = fake_loop_forever

        # This is mock for device dispatcher that always seems to be alive.
        _DeviceDispatcher_mock = RecursiveMagicMock()
        _DeviceDispatcher_mock.is_alive = MagicMock(return_value=True)
        _DeviceDispatcher_mock.exception = None

        _send_heartbeat_mock = MagicMock()

        self.cn = Connector(
            version="0.0.1", MqttClient=MagicMock, heartbeat_interval=0.1
        )
        self.cn._DeviceDispatcher = _DeviceDispatcher_mock
        self.cn._MqttClient = _MqttClient_mock
        self.cn._send_heartbeat = _send_heartbeat_mock
        self.cn.run_sensor_flow = MagicMock()
        self.cn.run()

        assert _send_heartbeat_mock.called
        assert _send_heartbeat_mock.call_count == 3

    def test_main_loop_broker_dispatcher_handling(self):
        """
        Simulate the the broker_dispatcher terminated, which should not happen
        during normal operation. Check that the connector emits a warning
        (alhough this warning may never be sent to the broker) and shuts down.
        """
        self.caplog.set_level(logging.ERROR, logger=self.logger_name)
        self.caplog.clear()

        # Creat a mock for the mqtt client that keeps the broker side
        # thread active for a bit, so it appears that the process is healthy.
        def fake_loop_forever():
            time.sleep(0.05)

        _MqttClient_mock = RecursiveMagicMock()
        _MqttClient_mock.loop_forever = fake_loop_forever

        # This is mock for device dispatcher that always seems to be alive.
        _DeviceDispatcher_mock = RecursiveMagicMock()
        _DeviceDispatcher_mock.is_alive = MagicMock(return_value=True)
        _DeviceDispatcher_mock.exception = None

        _send_heartbeat_mock = MagicMock()

        self.cn = Connector(
            version="0.0.1", MqttClient=MagicMock, heartbeat_interval=0.05
        )
        self.cn._DeviceDispatcher = _DeviceDispatcher_mock
        self.cn._MqttClient = _MqttClient_mock
        self.cn._send_heartbeat = _send_heartbeat_mock
        self.cn.run_sensor_flow = MagicMock()
        self.cn.run()

        records = self.caplog.records
        assert len(records) == 1
        assert records[0].levelname == "ERROR"
        assert "unexpected exception" in records[0].message
        assert "Shuting down." in records[0].message

    def test_main_loop_device_dispatcher_handling(self):
        """
        Simulate that the device dispatcher is not alive. We expect an
        error message and a shutdown of the connector.
        """
        self.caplog.set_level(logging.ERROR, logger=self.logger_name)
        self.caplog.clear()

        # Creat a mock for the mqtt client that keeps the broker side
        # thread active for a bit, so it appears that the process is healthy.
        def fake_loop_forever():
            time.sleep(0.05)

        _MqttClient_mock = RecursiveMagicMock()
        _MqttClient_mock.loop_forever = fake_loop_forever

        # This is mock for device dispatcher that always seems to be alive.
        _DeviceDispatcher_mock = RecursiveMagicMock()
        _DeviceDispatcher_mock.is_alive = MagicMock(return_value=False)
        _DeviceDispatcher_mock.exception = None

        _send_heartbeat_mock = MagicMock()

        self.cn = Connector(
            version="0.0.1", MqttClient=MagicMock, heartbeat_interval=0.05
        )
        self.cn._DeviceDispatcher = _DeviceDispatcher_mock
        self.cn._MqttClient = _MqttClient_mock
        self.cn._send_heartbeat = _send_heartbeat_mock
        self.cn.run_sensor_flow = MagicMock()
        self.cn.run()

        records = self.caplog.records
        assert len(records) == 1
        assert records[0].levelname == "ERROR"
        assert "unexpected exception" in records[0].message
        assert "Shuting down." in records[0].message

        # Also verify that the dispatcher has been check if it is alive.
        assert _DeviceDispatcher_mock.is_alive.called

    def test_main_loop_normal_exit_no_error(self):
        """
        Simulate that the device dispatcher is alive.
        We expect no error messags.
        """
        self.caplog.set_level(logging.WARNING, logger=self.logger_name)
        self.caplog.clear()

        # Creat a mock for the mqtt client that keeps the broker side
        # thread active for a bit, so it appears that the process is healthy.
        def fake_loop_forever():
            time.sleep(0.04)
            raise SystemExit()

        _MqttClient_mock = RecursiveMagicMock()
        _MqttClient_mock.loop_forever = fake_loop_forever

        # This is mock for device dispatcher that always seems to be alive.
        _DeviceDispatcher_mock = RecursiveMagicMock()
        _DeviceDispatcher_mock.is_alive = MagicMock(return_value=True)
        _DeviceDispatcher_mock.exception = None

        _send_heartbeat_mock = MagicMock()

        self.cn = Connector(
            version="0.0.1",
            MqttClient=MagicMock,
            heartbeat_interval=0.1,
            # Without this we would get a warning.
            device_dispatcher_kwargs={"target_func": MagicMock()},
        )
        self.cn._DeviceDispatcher = _DeviceDispatcher_mock
        self.cn._MqttClient = _MqttClient_mock
        self.cn._send_heartbeat = _send_heartbeat_mock
        self.cn.run_sensor_flow = MagicMock()
        self.cn.run()

        records = self.caplog.records
        assert len(records) == 0


class TestConnectorHandleIncomingMqttMsg(TestClassWithFixtures):

    fixture_names = ()

    def setup_method(self, method):

        self.test_CONNECTOR_NAME = "tpyco"
        self.test_SEND_RAW_MESSAGE_TO_DB = "FALSE"
        self.test_DEBUG = "FALSE"
        self.test_MQTT_BROKER_HOST = "localhost"
        self.test_MQTT_BROKER_PORT = "1883"

        # Expose the config as environment variables as would be done
        # by a docker entrypoint script.
        os.environ["CONNECTOR_NAME"] = self.test_CONNECTOR_NAME
        os.environ["SEND_RAW_MESSAGE_TO_DB"] = self.test_SEND_RAW_MESSAGE_TO_DB
        os.environ["DEBUG"] = self.test_DEBUG
        os.environ["MQTT_BROKER_HOST"] = self.test_MQTT_BROKER_HOST
        os.environ["MQTT_BROKER_PORT"] = self.test_MQTT_BROKER_PORT

        self.cn = Connector(version="0.0.1")

        # Overload some attributes/methods for testing.
        self.cn.MQTT_TOPIC_DATAPOINT_MAP = "tpyco/datapoint_map"
        self.vaudm_mock = MagicMock()
        self.cn._validate_and_update_datapoint_map = self.vaudm_mock
        self.raf_mock = MagicMock()
        self.cn.run_actuator_flow = self.raf_mock

        # Wire through the connector object as Connector.run would do.
        self.test_userdata = {"self": self.cn}

    def test_datapoint_msg_triggers_update(self):
        """
        Verify that a message with a datapoint_map triggers the respective
        update method.
        """
        test_payload = MagicMock()
        test_topic = self.cn.MQTT_TOPIC_DATAPOINT_MAP

        test_msg = MagicMock()
        test_msg.topic = test_topic
        test_msg.payload = test_payload

        self.cn._handle_incoming_mqtt_msg(
            client=MagicMock(),
            userdata=self.test_userdata,
            msg=test_msg,
        )

        assert self.vaudm_mock.called
        expected_vaudm_kwargs = {"datapoint_map_json": test_payload}
        actual_vaudm_kwargs = self.vaudm_mock.call_args.kwargs
        assert actual_vaudm_kwargs == expected_vaudm_kwargs

    def test_actuator_msg_triggers_run_actuator_flow(self):
        """
        Verify that a message that could be directed to an actuator
        datapoint triggers the run_actuator_flow method in order to
        send this message to the device.
        """
        test_payload = MagicMock()
        # Arbitrary topic, that doesn't collide with MQTT_TOPIC_DATAPOINT_MAP
        test_topic = "tpyco/msgs/msg_001"

        test_msg = MagicMock()
        test_msg.topic = test_topic
        test_msg.payload = test_payload

        self.cn._handle_incoming_mqtt_msg(
            client=MagicMock(),
            userdata=self.test_userdata,
            msg=test_msg,
        )

        assert self.raf_mock.called
        expected_raf_kwargs = {
            "topic": test_topic,
            "value_msg_json": test_payload,
        }
        actual_raf_kwargs = self.raf_mock.call_args.kwargs
        assert actual_raf_kwargs == expected_raf_kwargs


class TestConnectorValidateAndUpdateDatapointMap(TestClassWithFixtures):

    fixture_names = ("caplog",)

    def setup_method(self, method):

        self.test_CONNECTOR_NAME = "tpyco"
        self.test_SEND_RAW_MESSAGE_TO_DB = "FALSE"
        self.test_DEBUG = "FALSE"
        self.test_MQTT_BROKER_HOST = "localhost"
        self.test_MQTT_BROKER_PORT = "1883"

        # Expose the config as environment variables as would be done
        # by a docker entrypoint script.
        os.environ["CONNECTOR_NAME"] = self.test_CONNECTOR_NAME
        os.environ["SEND_RAW_MESSAGE_TO_DB"] = self.test_SEND_RAW_MESSAGE_TO_DB
        os.environ["DEBUG"] = self.test_DEBUG
        os.environ["MQTT_BROKER_HOST"] = self.test_MQTT_BROKER_HOST
        os.environ["MQTT_BROKER_PORT"] = self.test_MQTT_BROKER_PORT

        self.cn = Connector(version="0.0.1")
        self.cn.datapoint_map = {"sensor": {}, "actuator": {}}
        # This is the name of the logger used in pyconnector_template.py
        self.logger_name = "pyconnector"

        # Overload some attributes for testing.
        self.cn.mqtt_client = MagicMock()

    def test_valid_datapoint_map_is_stored(self):
        """
        Verify that valid datapoint_map objects are stored as expected.
        """
        datapoint_map = {
            "sensor": {
                "Channel__P__value__0": "example-connector/msgs/0001",
                "Channel__P__unit__0": "example-connector/msgs/0002",
            },
            "actuator": {
                "example-connector/msgs/0003": "Channel__P__setpoint__0",
            },
        }

        self.cn._validate_and_update_datapoint_map(
            datapoint_map_json=json.dumps(datapoint_map)
        )

        assert self.cn.datapoint_map == datapoint_map

    def test_datapoint_map_with_missing_sensor_key_fails(self):
        """
        A datapoint_object must have a "sensor" entry by convention.
        """
        # Set up a new and empty logger for the test
        self.caplog.set_level(logging.INFO, logger=self.logger_name)
        self.caplog.clear()

        datapoint_map = {
            "actuator": {
                "example-connector/msgs/0003": "Channel__P__setpoint__0",
            }
        }

        self.cn._validate_and_update_datapoint_map(
            datapoint_map_json=json.dumps(datapoint_map)
        )

        records = self.caplog.records
        assert len(records) == 1
        assert records[0].levelname == "ERROR"
        assert "No sensor key" in records[0].message

    def test_datapoint_map_with_missing_actuator_key_fails(self):
        """
        A datapoint_object must have a "actuator" entry by convention.
        """
        # Set up a new and empty logger for the test
        self.caplog.set_level(logging.INFO, logger=self.logger_name)
        self.caplog.clear()

        datapoint_map = {
            "sensor": {
                "Channel__P__value__0": "example-connector/msgs/0001",
                "Channel__P__unit__0": "example-connector/msgs/0002",
            },
        }

        self.cn._validate_and_update_datapoint_map(
            datapoint_map_json=json.dumps(datapoint_map)
        )

        records = self.caplog.records
        assert len(records) == 1
        assert records[0].levelname == "ERROR"
        assert "No actuator key" in records[0].message

    def test_datapoint_map_with_missing_sensor_dict_fails(self):
        """
        A datapoint_object must have a dict value under sensor entry by
        convention.
        """
        # Set up a new and empty logger for the test
        self.caplog.set_level(logging.INFO, logger=self.logger_name)
        self.caplog.clear()

        datapoint_map = {
            "sensor": None,
            "actuator": {
                "example-connector/msgs/0003": "Channel__P__setpoint__0",
            },
        }

        self.cn._validate_and_update_datapoint_map(
            datapoint_map_json=json.dumps(datapoint_map)
        )

        records = self.caplog.records
        assert len(records) == 1
        assert records[0].levelname == "ERROR"
        assert "Sensor entry in datapoint_map" in records[0].message

    def test_datapoint_map_with_missing_actuator_dict_fails(self):
        """
        A datapoint_object must have a dict value under actuator entry by
        convention.
        """
        # Set up a new and empty logger for the test
        self.caplog.set_level(logging.INFO, logger=self.logger_name)
        self.caplog.clear()

        datapoint_map = {
            "sensor": {
                "Channel__P__value__0": "example-connector/msgs/0001",
                "Channel__P__unit__0": "example-connector/msgs/0002",
            },
            "actuator": None,
        }

        self.cn._validate_and_update_datapoint_map(
            datapoint_map_json=json.dumps(datapoint_map)
        )

        records = self.caplog.records
        assert len(records) == 1
        assert records[0].levelname == "ERROR"
        assert "Actuator entry in datapoint_map" in records[0].message

    def test_new_actuator_entry_triggers_subscribe(self):
        """
        A new entry in actuator part of the datapoint_map should trigger
        a subscribe action as the connector should subscribe to the topic
        of the newly selected datapoint.
        """
        # Assume this map has been set up before.
        datapoint_map_old = {
            "sensor": {},
            "actuator": {
                "example-connector/msgs/0003": "Channel__P__setpoint__0",
            },
        }
        self.cn.datapoint_map = datapoint_map_old

        datapoint_map_update = {
            "sensor": {},
            "actuator": {
                "example-connector/msgs/0003": "Channel__P__setpoint__0",
                "example-connector/msgs/0004": "Channel__T__setpoint__0",
            },
        }
        self.cn._validate_and_update_datapoint_map(
            datapoint_map_json=json.dumps(datapoint_map_update)
        )

        expceted_call_count = 1
        actual_call_count = self.cn.mqtt_client.subscribe.call_count
        assert actual_call_count == expceted_call_count

        expected_topic = "example-connector/msgs/0004"
        actual_topic = self.cn.mqtt_client.subscribe.call_args.kwargs["topic"]
        assert actual_topic == expected_topic

        # Also check that the subscribe is requested with maximum QOS request
        # to prevent message losses for actuator setpoints.
        expected_qos = 2
        actual_qos = self.cn.mqtt_client.subscribe.call_args.kwargs["qos"]
        assert actual_qos == expected_qos

    def test_removed_actuator_entry_triggers_unsubscribe(self):
        """
        A removed entry in actuator part of the datapoint_map should trigger
        an unsubscribe action as the connector should no longer receive
        messages for that actuator.
        """
        # Assume this map has been set up before.
        datapoint_map_old = {
            "sensor": {},
            "actuator": {
                "example-connector/msgs/0003": "Channel__P__setpoint__0",
                "example-connector/msgs/0004": "Channel__T__setpoint__0",
            },
        }
        self.cn.datapoint_map = datapoint_map_old

        datapoint_map_update = {
            "sensor": {},
            "actuator": {
                "example-connector/msgs/0004": "Channel__T__setpoint__0",
            },
        }
        self.cn._validate_and_update_datapoint_map(
            datapoint_map_json=json.dumps(datapoint_map_update)
        )

        expceted_call_count = 1
        actual_call_count = self.cn.mqtt_client.unsubscribe.call_count
        assert actual_call_count == expceted_call_count

        expected_topic = "example-connector/msgs/0003"
        actual_topic = self.cn.mqtt_client.unsubscribe.call_args.kwargs["topic"]
        assert actual_topic == expected_topic


class TestConnectorUpdateAvailableDatapoints(TestClassWithFixtures):

    fixture_names = []

    def setup_method(self, method):

        self.test_CONNECTOR_NAME = "tpyco"
        self.test_SEND_RAW_MESSAGE_TO_DB = "FALSE"
        self.test_DEBUG = "FALSE"
        self.test_MQTT_BROKER_HOST = "localhost"
        self.test_MQTT_BROKER_PORT = "1883"

        # Expose the config as environment variables as would be done
        # by a docker entrypoint script.
        os.environ["CONNECTOR_NAME"] = self.test_CONNECTOR_NAME
        os.environ["SEND_RAW_MESSAGE_TO_DB"] = self.test_SEND_RAW_MESSAGE_TO_DB
        os.environ["DEBUG"] = self.test_DEBUG
        os.environ["MQTT_BROKER_HOST"] = self.test_MQTT_BROKER_HOST
        os.environ["MQTT_BROKER_PORT"] = self.test_MQTT_BROKER_PORT

        self.cn = Connector(version="0.0.1")

        # Overload some attributes for testing.
        self.cn.mqtt_client = MagicMock()
        self.cn.MQTT_TOPIC_AVAILABLE_DATAPOINTS = "tpyco/available_datapoints"

    def test_update_without_new_keys_publishes_not(self):
        """
        Updateing available_datapoints without new datapoint keys should
        not trigger sending an update via MQTT.
        """
        self.cn.available_datapoints = {
            "sensor": {
                "Channel__P__value__0": 0.122,
                "Channel__P__unit__0": "kW",
            },
            "actuator": {
                "Channel__P__setpoint__0": 0.4,
            },
        }

        available_datapoints_update = {
            "sensor": {
                "Channel__P__value__0": 9.222,
                "Channel__P__unit__0": "kW",
            },
            "actuator": {
                "Channel__P__setpoint__0": 6.4,
            },
        }
        self.cn._update_available_datapoints(
            available_datapoints=available_datapoints_update
        )

        expected_call_count = 0
        actual_call_count = self.cn.mqtt_client.publish.call_count
        assert actual_call_count == expected_call_count

    def test_update_without_new_keys_updates_example_values(self):
        """
        Updateing available_datapoints without new datapoint keys should
        update the example values so more recent values are published with
        the next new datapoint.
        """
        self.cn.available_datapoints = {
            "sensor": {
                "Channel__P__value__0": 0.122,
                "Channel__P__unit__0": "kW",
            },
            "actuator": {
                "Channel__P__setpoint__0": 0.4,
            },
        }

        available_datapoints_update = {
            "sensor": {
                "Channel__P__value__0": 9.222,
            },
            "actuator": {
                "Channel__P__setpoint__0": 6.4,
            },
        }
        self.cn._update_available_datapoints(
            available_datapoints=available_datapoints_update
        )

        expected_available_datapoints = {
            "sensor": {
                "Channel__P__value__0": 9.222,
                "Channel__P__unit__0": "kW",
            },
            "actuator": {
                "Channel__P__setpoint__0": 6.4,
            },
        }
        actual_available_datapoints = self.cn.available_datapoints
        assert actual_available_datapoints == expected_available_datapoints

    def test_update_with_new_key_triggers_publish(self):
        """
        A new key should trigger publishing the latest available_datapoints
        dict.
        """
        for dp_type in ["sensor", "actuator"]:

            self.cn.available_datapoints = {
                "sensor": {
                    "Channel__P__value__0": 0.122,
                    "Channel__P__unit__0": "kW",
                },
                "actuator": {
                    "Channel__P__setpoint__0": 0.4,
                },
            }

            available_datapoints_update = {"sensor": {}, "actuator": {}}
            available_datapoints_update[dp_type]["Channel__Q__sp__0"] = 6.4
            self.cn._update_available_datapoints(
                available_datapoints=available_datapoints_update
            )

            # Verify that the updated dict is stored.
            expected_available_datapoints = {
                "sensor": {
                    "Channel__P__value__0": 0.122,
                    "Channel__P__unit__0": "kW",
                },
                "actuator": {
                    "Channel__P__setpoint__0": 0.4,
                },
            }
            expected_available_datapoints[dp_type]["Channel__Q__sp__0"] = 6.4
            actual_available_datapoints = self.cn.available_datapoints
            assert actual_available_datapoints == expected_available_datapoints

            # Check that it is also published on the correct topic.
            mqtt_client = self.cn.mqtt_client
            expected_payload = json.dumps(expected_available_datapoints)
            actual_payload = mqtt_client.publish.call_args.kwargs["payload"]
            assert actual_payload == expected_payload

            expected_topic = self.cn.MQTT_TOPIC_AVAILABLE_DATAPOINTS
            actual_topic = mqtt_client.publish.call_args.kwargs["topic"]
            assert actual_topic == expected_topic


class TestConnectorSendHeartbeat(TestClassWithFixtures):

    fixture_names = ()

    def setup_method(self, method):

        self.test_CONNECTOR_NAME = "tpyco"
        self.test_SEND_RAW_MESSAGE_TO_DB = "FALSE"
        self.test_DEBUG = "FALSE"
        self.test_MQTT_BROKER_HOST = "localhost"
        self.test_MQTT_BROKER_PORT = "1883"

        # Expose the config as environment variables as would be done
        # by a docker entrypoint script.
        os.environ["CONNECTOR_NAME"] = self.test_CONNECTOR_NAME
        os.environ["SEND_RAW_MESSAGE_TO_DB"] = self.test_SEND_RAW_MESSAGE_TO_DB
        os.environ["DEBUG"] = self.test_DEBUG
        os.environ["MQTT_BROKER_HOST"] = self.test_MQTT_BROKER_HOST
        os.environ["MQTT_BROKER_PORT"] = self.test_MQTT_BROKER_PORT

        self.cn = Connector(version="0.0.1")
        self.cn._heartbeat_interval = 22.1
        self.cn.mqtt_client = MagicMock()

    def test_heartbeat_msg_format_correct(self):
        """
        Check that the message format of the heartbeat message is generally
        correct.
        """
        self.cn._send_heartbeat()

        actual_hb_msg = json.loads(
            self.cn.mqtt_client.publish.call_args.kwargs["payload"]
        )

        assert "this_heartbeats_timestamp" in actual_hb_msg
        assert "next_heartbeats_timestamp" in actual_hb_msg
        assert isinstance(actual_hb_msg["this_heartbeats_timestamp"], int)
        assert isinstance(actual_hb_msg["next_heartbeats_timestamp"], int)

    def test_heartbeat_msg_topic_correct(self):
        """
        Verify that the heartbeat message is published on the correct topic.
        """
        self.cn._send_heartbeat()

        actual_hb_topic = self.cn.mqtt_client.publish.call_args.kwargs["topic"]
        expected_hb_topic = self.cn.MQTT_TOPIC_HEARTBEAT
        assert actual_hb_topic == expected_hb_topic

    def test_this_heartbeat_timestamp_correct(self):
        """
        The heartbeat message contains two timestamps, one for now and one
        for the next expected heartbeat. Check that this_heartbeats_timestamp
        is set to the time the method is called.
        """

        start_ts = round(datetime.now(tz=timezone.utc).timestamp() * 1000)

        self.cn._send_heartbeat()
        actual_hb_msg = json.loads(
            self.cn.mqtt_client.publish.call_args.kwargs["payload"]
        )
        actual_this_hb_ts = actual_hb_msg["this_heartbeats_timestamp"]

        # Check that the actual timestamp is between the time this function
        # has started and 1 seconds later, which should be ok even on very
        # slow machines. -1 on min, in case the round above has rounded up.
        expected_this_hb_ts_min = start_ts - 1
        expected_this_hb_ts_max = start_ts + 1000
        assert actual_this_hb_ts >= expected_this_hb_ts_min
        assert actual_this_hb_ts < expected_this_hb_ts_max

    def test_next_heartbeat_timestamp_correct(self):
        """
        The heartbeat message contains two timestamps, one for now and one
        for the next expected heartbeat. Check that next_heartbeats_timestamp
        is set to the time the method is called + heartbeat_interval.
        """

        start_ts = round(datetime.now(tz=timezone.utc).timestamp() * 1000)

        self.cn._send_heartbeat()
        actual_hb_msg = json.loads(
            self.cn.mqtt_client.publish.call_args.kwargs["payload"]
        )
        actual_next_hb_ts = actual_hb_msg["next_heartbeats_timestamp"]

        # Check that the actual timestamp is between the time this function
        # has started and 1 seconds later plus the heartbeat intverval, which
        # should be ok even on very slow machines. -1 on min, in case
        # the round above has rounded up.
        expected_next_hb_ts_min = (
            start_ts - 1 + self.cn._heartbeat_interval * 1000
        )
        expected_next_hb_ts_max = expected_next_hb_ts_min + 1001
        assert actual_next_hb_ts >= expected_next_hb_ts_min
        assert actual_next_hb_ts < expected_next_hb_ts_max

    def test_heartbeat_msg_interval_correct(self):
        """
        The heartbeat message contains two timestamps, one for now and one
        for the next expected heartbeat. Check here that the interval between
        the two matches the _heartbeat_interval of the connector.
        """
        self.cn._send_heartbeat()
        actual_hb_msg = json.loads(
            self.cn.mqtt_client.publish.call_args.kwargs["payload"]
        )
        actual_this_hb_ts = actual_hb_msg["this_heartbeats_timestamp"]
        actual_next_hb_ts = actual_hb_msg["next_heartbeats_timestamp"]

        actual_ts_difference = actual_next_hb_ts - actual_this_hb_ts
        expected_ts_difference = self.cn._heartbeat_interval * 1000
        assert actual_ts_difference == expected_ts_difference
